{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walmart Sales & Performance Analysis\n",
    "This project showcases end-to-end data analysis from loading and cleaning a Walmart sales dataset in Python to exporting it into MySQL for advanced SQL querying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importing Required Libraries\n",
    "To start the analysis, essential Python libraries like Pandas for data handling and SQLAlchemy/MySQL Connector for database integration are imported. \n",
    "This ensures we can process the Walmart sales dataset and store results in a relational database for querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Loading Walmart Sales Dataset\n",
    "The Walmart sales dataset is loaded from a CSV file into a Pandas DataFrame for analysis.  \n",
    "This step ensures the raw dataset is in memory and ready for preprocessing and exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Walmart.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data Cleaning\n",
    "- Removing duplicates and missing values.\n",
    "- Converting unit_price from string to float.\n",
    "- Creating a new feature total_price by multiplying unit_price and quantity.\n",
    "These steps ensure the dataset is consistent, accurate, and ready for KPI calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n",
    "df.shape\n",
    "\n",
    "df.describe()\n",
    "\n",
    "df.duplicated().sum()\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.shape\n",
    "\n",
    "df['unit_price'] = df['unit_price'].str.replace('$', '')\n",
    "\n",
    "df['unit_price'] = df['unit_price'].astype(float)\n",
    "\n",
    "df['total_price'] = df['unit_price'] * df['quantity']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. SQLAlchemy Engine Creation\n",
    "A SQLAlchemy engine is created to connect the cleaned dataset to a MySQL database.  \n",
    "This will allow to export of processed data for advanced SQL queries and integration with PowerBI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "user='root'\n",
    "password='1977'\n",
    "host='localhost'\n",
    "port='3306'\n",
    "database='walmartdb'\n",
    "\n",
    "engine=create_engine(f'mysql+mysqlconnector://{user}:{password}@{host}:{port}/{database}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Exporting Cleaned Data to MySQL\n",
    "The cleaned Walmart dataset is exported from Pandas to a MySQL database table named walmart_sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(name='walmart_sales', con=engine, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
